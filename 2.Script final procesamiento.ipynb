{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas_summary import DataFrameSummary\n",
    "%matplotlib\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 10)\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True, font_scale=1.5)\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab \n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm, probplot, boxcox\n",
    "from scipy.special import boxcox1p\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFECV, SelectFromModel\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, OrthogonalMatchingPursuit, Lasso, LassoLarsIC, ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import SGDRegressor, PassiveAggressiveRegressor, HuberRegressor, BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir tabla con datos internos y externos\n",
    "tablin = pd.read_csv(r'C:\\Users\\Marta\\Scripts - Presentación\\tablin_datos_externos.csv', \n",
    "                   sep=';', engine=\"python\", decimal=',', encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesar las fechas\n",
    "fechas = list(tablin.Fecha.drop_duplicates())\n",
    "dictionary_dates_date_to_num = {}\n",
    "dictionary_dates_num_to_date = {}\n",
    "for date_iter in range(len(fechas)):\n",
    "    dictionary_dates_date_to_num[fechas[date_iter]] = date_iter\n",
    "    dictionary_dates_num_to_date[date_iter] = fechas[date_iter]\n",
    "\n",
    "dictionary_dates_num_to_date[56] = '01/01/2019'\n",
    "dictionary_dates_num_to_date[57] = '01/04/2019'\n",
    "dictionary_dates_num_to_date[58] = '01/07/2019'\n",
    "dictionary_dates_num_to_date[59] = '01/10/2019'\n",
    "dictionary_dates_num_to_date[60] = '01/01/2020'\n",
    "dictionary_dates_num_to_date[61] = '01/04/2020'\n",
    "dictionary_dates_num_to_date[62] = '01/07/2020'\n",
    "dictionary_dates_num_to_date[63] = '01/10/2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar outliers\n",
    "tablin= tablin[np.abs(tablin['Hipotecas']-tablin['Hipotecas'].mean()) <= (3*tablin['Hipotecas'].std())] \n",
    "\n",
    "#Log transformation\n",
    "tablin['Hipotecas_log'] = np.log(tablin['Hipotecas'])\n",
    "tablin['Tasa desempleo_log'] = np.log(tablin['Tasa desempleo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar nulos y duplicados\n",
    "tablin=tablin.dropna()\n",
    "tablin= tablin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseo_fecha_cuatrimeste(row):\n",
    "    if row[1] == 'Primero':\n",
    "        date = '01/01/'\n",
    "    elif row[1] == 'Segundo':\n",
    "        date = '01/04/'\n",
    "    elif row[1] == 'Tercero':\n",
    "        date = '01/07/'\n",
    "    elif row[1] == 'Cuarto':\n",
    "        date = '01/10/'\n",
    "    return date+str(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Procesar\n",
    "tablin = tablin[tablin['SUPADAPT']>1]\n",
    "tablin['Index'] = tablin.index \n",
    "data_pred= tablin\n",
    "data_pred = data_pred.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data_pred['Fecha_num']=le.fit_transform(data_pred['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recodificar\n",
    "data_pred= data_pred.replace('SI', '1')\n",
    "data_pred= data_pred.replace('NO', '0')\n",
    "data_pred= data_pred.replace('LIBRE', 'Libre' )\n",
    "data_pred= data_pred.replace('ESPECIAL', 'Especial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123537, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminar duplicados y nulos\n",
    "\n",
    "data_pred = data_pred.drop_duplicates()\n",
    "data_pred= data_pred.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesar EDIF_FECHA_CONSTRUCCION \n",
    "\n",
    "data_pred.loc[:,'EDIF_FECHA_CONSTRUCCION'] = data_pred['EDIF_FECHA_CONSTRUCCION'].apply(lambda s: (s[5:9]))\n",
    "data_pred['EDIF_FECHA_CONSTRUCCION']= data_pred.loc[:,['EDIF_FECHA_CONSTRUCCION']].replace(\"\", np.nan)\n",
    "data_pred= data_pred.dropna() \n",
    "\n",
    "#Convertimos la fecha de construccion a una variable de antigüedad de la vivienda\n",
    "data_pred['EDIF_FECHA_CONSTRUCCION']= data_pred['EDIF_FECHA_CONSTRUCCION'].astype(int)\n",
    "indexNames = data_pred[(data_pred['EDIF_FECHA_CONSTRUCCION'] < 1800)].index\n",
    "data_pred.drop(indexNames , inplace=True)\n",
    "data_pred['EDIF_FECHA_CONSTRUCCION']= data_pred['EDIF_FECHA_CONSTRUCCION'] - 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear variable de variación del precio de la vivienda por año\n",
    "#Ordenar por fecha (quarterly)\n",
    "data_pred= data_pred.sort_values('Fecha_num')\n",
    "\n",
    "#Agrupar por fecha y calcular la media del precio de las viviendas\n",
    "data_pred['Variacion'] = data_pred.groupby('Fecha_num')['IMPTOTAL'].transform('mean')\n",
    "\n",
    "#Calcular la variacion de la media del precio de las viviendas respecto al trimestre anterior\n",
    "c= data_pred.loc[:,['Fecha_num', 'Variacion']]\n",
    "c= c.drop_duplicates()\n",
    "c['change'] = c['Variacion'].pct_change()\n",
    "c=c.fillna(0)\n",
    "data_pred= data_pred.merge(c.drop(['Variacion'],1), how='left', on=['Fecha_num'])\n",
    "data_pred= data_pred.drop(columns='Variacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_del = ['DESPOBLACI','CODPOSTAL', 'CODPROVINC', 'Hipotecas', 'Tasa desempleo', 'Index']\n",
    "for col in columns_to_del:\n",
    "    del data_pred[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignar el tipo de variables (las siguientes son strings)\n",
    "for col in ['EDIF_CALIDAD_CONSTRU_COD','EDIF_EST_CONSERVACION_COD','VIV_ORIENTACION_COD','EDIF_FECHA_CONSTRUCCION']:\n",
    "    data_pred.loc[:,col] = data_pred.loc[:,col].apply(lambda s: str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quitar outliers y guardar la tabla final\n",
    "\n",
    "data_pred= data_pred[np.abs(data_pred['IMPTOTAL']-data_pred['IMPTOTAL'].mean()) <= (3*data_pred['IMPTOTAL'].std())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar nombre de algunas columnas\n",
    "data_pred=data_pred.rename(columns = {'SUPADAPT':'SUPERF_ADOPTADA', 'DESMUNIC': 'Municipio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_index = data_pred.loc[:,['MATRICULA','Fecha_num']].groupby('MATRICULA').idxmax()   #agrupamos por matrícula (la fecha más reciente)\n",
    "data_pred = data_pred.loc[data_pred_index['Fecha_num']]   #filtramos y nos quedamos sin duplicados de la misma vivienda con distinta fecha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.to_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Modelo evolución precios\\Datos - copia - Marta\\tabla.csv', \n",
    "                   sep=';', decimal=',', encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84735, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
